# coalitions-for-tool-use - Assessing Critiquing

This research was performed by IBM Research UK and investigates if coalitions of open-sourced, pretrained (non-fine-tuned) Large Language Models, can work together to assist in complex workflows through agentic augmentation with external tools. 

In this directory we share our assessment strategy for examining which pre-trained model performs the best at critiquing plans for use within our coalition system.

For assessing a systems ability to operate in the tool use domain it has to excel in the following sub-tasks:
1. (Planning) Given an intent/prompt, plan the tools to use (LLM driven)
1. (Slot filling/Execution) Slot fill the parameters for the tools to be used (LLM driven)
1. (Slot filling/Execution) Execute the tool with the inferred parameters (System/programmatically driven)
1. (Response Forming) Formulate a meaningful response to the initial query, based on the responses of the executed tools (LLM driven)

In this directory we assess the model best suited to critique the generated plans from the planner component to improve and correct the plans to execute. 

## Experimental Setup
Dataset Used:
- Custom Data - [link](./final_planner_prompts_with_pollutions.json).

The models assessed:
- `mistralai/mistral-7b-instruct-v0-2`
- `mistralai/mixtral-8x7b-instruct-v01`
- `meta-llama/llama-2-70b-chat`
- `google/flan-ul2`
- `codellama/codellama-34b-instruct`

##Â Strategy:

For this assessment a dataset has been built containing polluted plans of different categories:
- Incorrect ordering of steps in the generated plan
- Missing step in the generated plan
- Addition step in the generated plan
- Many additional steps in the generated plan

The task of the model is to correct these pollutions. Each model is presented 3 levels of critique to understand the type of "feedback" they need to correct the pollution:
1. General Critique - A pollution agnostic, general feedback comment such as `Can this plan be simplified or improved?`
2. Assisted Critique - A pollution specific, general feedback comment such as `It seems like the plan has some steps in the wrong order, can the plan be corrected?`
3. Explicit Critique - A pollution specific, explicit comment requesting the desired correction such as `Reorder step 1 and 2.`

Based on these cases and feedbacks we can assess how good a model is at correcting bad plans and the type of feedback it requires to fix those plans. 

## Running the Evaluations

In this directory the data collected from locally running the critiquing evaluations are provided. 

Although the summarised results are provided already in the `results` directory these files can be regenerated by using the `run_critique_prompts.py` script to recreate the evaluation and the metrics collected. 

### Reproducing the results:

1. Follow the guide in the root directory to setup your local environment
1. Change into this directory (if in the root directory): `cd assessing-critiquing`
1. Based on your access, you may need to setup connection to a watsonx.ai deployment and update the provided `run_critique_prompts.py` script to utilise the `ibm-watsonx-ai` SDK - see [here](https://ibm.github.io/watsonx-ai-python-sdk/install.html).
1. Export connection to your watsonx.ai instance. For example:
    ```bash
    export GENAI_KEY=<apikey to connect to watsonx.ai instance>
    export GENAI_API=<address of watsonx.ai instance>
    ```
1. Choose the model to test, for example:
    ```python
    # MODEL_ID="mistralai/mistral-7b-instruct-v0-2"
    # MODEL_ID="mistralai/mixtral-8x7b-instruct-v01"
    # MODEL_ID="meta-llama/llama-2-70b-chat"
    # MODEL_ID="google/flan-ul2"
    # MODEL_ID="codellama/codellama-34b-instruct"
    ```
1. Run the evaluation script, for example:
    ```bash
    MODEL_ID="google/flan-ul2" python run_critique_prompts.py
    ```
1. Examine the generated results file: `critique_prompting_results_rerun.json`. 

For any queries or feedback please email: prattyush.mangal@ibm.com
